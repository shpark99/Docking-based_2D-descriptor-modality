{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "682dd1d7-9a56-4514-ab81-878861c10cc9",
      "metadata": {
        "id": "682dd1d7-9a56-4514-ab81-878861c10cc9"
      },
      "source": [
        "# test data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f568bfc1-6ce9-4e36-8e85-d60bce6253ea",
      "metadata": {
        "id": "f568bfc1-6ce9-4e36-8e85-d60bce6253ea"
      },
      "source": [
        "## test data 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "514b2134-32a7-44f5-b317-7d08f5e478e0",
      "metadata": {
        "id": "514b2134-32a7-44f5-b317-7d08f5e478e0"
      },
      "source": [
        "### Part 1: 디스크립터 계산 & with_desc 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "081368d1-8e1e-4e17-920a-8fc26d817340",
      "metadata": {
        "id": "081368d1-8e1e-4e17-920a-8fc26d817340",
        "outputId": "9c1e2600-ce8a-48f3-e54c-3d41b524d262"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[INFO][P1] Processing single file: /home/ssm-user/LAIDD/tox21/Data/test_data/test_data.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[02:44:05] Can't kekulize mol.  Unkekulized atoms: 4 5 6 7 10\n",
            "[02:44:08] Can't kekulize mol.  Unkekulized atoms: 6 7 8 9 10 11 12 13 14\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[READY][P1] saved -> /home/ssm-user/LAIDD/tox21/Data/test_data/test_data_with_desc.csv (rows=645, cols=219)\n"
          ]
        }
      ],
      "source": [
        "# ===================== Part 1: 디스크립터 계산 & with_desc 저장 =====================\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 단일 입력/출력 경로\n",
        "DATA_FILE = \" \"\n",
        "OUT_DIR   = \" \"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# RDKit 2D descriptor 유틸\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "try:\n",
        "    from rdkit.Chem import Descriptors3D\n",
        "    desc3d = {n for n, _ in Descriptors3D._descList}\n",
        "except Exception:\n",
        "    desc3d = set()\n",
        "\n",
        "DESC_2D_NAMES = [n for n, _ in Descriptors._descList if n not in desc3d]\n",
        "from rdkit.ML.Descriptors.MoleculeDescriptors import MolecularDescriptorCalculator\n",
        "_calc = MolecularDescriptorCalculator(DESC_2D_NAMES)\n",
        "\n",
        "def rdkit_2d_descriptors_from_series(smiles_series: pd.Series,\n",
        "                                     keep_all_rows: bool = True) -> pd.DataFrame:\n",
        "    rows, idxs = [], []\n",
        "    for idx, smi in smiles_series.items():\n",
        "        smi = \"\" if pd.isna(smi) else str(smi).strip()\n",
        "        if not smi:\n",
        "            if keep_all_rows:\n",
        "                rows.append([np.nan] * len(DESC_2D_NAMES)); idxs.append(idx)\n",
        "            continue\n",
        "        mol = Chem.MolFromSmiles(smi)\n",
        "        if mol is None:\n",
        "            if keep_all_rows:\n",
        "                rows.append([np.nan] * len(DESC_2D_NAMES)); idxs.append(idx)\n",
        "            continue\n",
        "        try:\n",
        "            vals = list(_calc.CalcDescriptors(mol))\n",
        "        except Exception:\n",
        "            vals = [np.nan] * len(DESC_2D_NAMES)\n",
        "        rows.append(vals); idxs.append(idx)\n",
        "    return pd.DataFrame(rows, columns=DESC_2D_NAMES, index=idxs)\n",
        "\n",
        "def add_rdkit_2d_descriptors(df: pd.DataFrame,\n",
        "                             smiles_col: str = \"SMILES\",\n",
        "                             keep_all_rows: bool = False) -> pd.DataFrame:\n",
        "    desc_df = rdkit_2d_descriptors_from_series(df[smiles_col], keep_all_rows=keep_all_rows)\n",
        "    # keep_all_rows=False → RDKit 계산 성공한 행만 남도록 inner-join 효과\n",
        "    return df.join(desc_df, how=\"inner\") if not keep_all_rows else pd.concat([df, desc_df.reindex(df.index)], axis=1)\n",
        "\n",
        "# --- 메인  ---\n",
        "assay_name = os.path.splitext(os.path.basename(DATA_FILE))[0]\n",
        "print(f\"\\n[INFO][P1] Processing single file: {DATA_FILE}\")\n",
        "\n",
        "# 1) 로드\n",
        "df = pd.read_csv(DATA_FILE, dtype=str, engine=\"python\")\n",
        "\n",
        "# 2) 필수 컬럼 확인 (SMILES, Sample ID만 필요)\n",
        "required = {\"SMILES\", \"Sample ID\"}\n",
        "if not required.issubset(df.columns):\n",
        "    raise ValueError(f\"Input must have SMILES and Sample ID columns. Found: {list(df.columns)}\")\n",
        "\n",
        "# 3) 문자열 정리 + 빈 SMILES 제거(로그용)\n",
        "df[\"SMILES\"] = df[\"SMILES\"].astype(str).str.strip()\n",
        "df[\"Sample ID\"] = df[\"Sample ID\"].astype(str).str.strip()\n",
        "before = len(df)\n",
        "df = df[df[\"SMILES\"].str.len() > 0]\n",
        "removed_empty = before - len(df)\n",
        "if removed_empty > 0:\n",
        "    print(f\"  -> Removed {removed_empty} rows with empty SMILES.\")\n",
        "\n",
        "# 4) 디스크립터 계산 (유효 SMILES만)\n",
        "df_with_desc = add_rdkit_2d_descriptors(df, smiles_col=\"SMILES\", keep_all_rows=False)\n",
        "\n",
        "# 5) 저장: 정제 없이 그대로 저장\n",
        "out_path = os.path.join(OUT_DIR, f\"{assay_name}_with_desc.csv\")\n",
        "df_with_desc.to_csv(out_path, index=False)\n",
        "\n",
        "print(f\"[READY][P1] saved -> {out_path} (rows={len(df_with_desc)}, cols={len(df_with_desc.columns)})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d5a2817-94c1-4b2b-ac02-db0ebf35465e",
      "metadata": {
        "id": "5d5a2817-94c1-4b2b-ac02-db0ebf35465e"
      },
      "source": [
        "### Part 2: _with_desc.csv 전처리 후 _2Ddesc.csv 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ffd8bac-416d-4c5a-8a4b-683392c19051",
      "metadata": {
        "id": "7ffd8bac-416d-4c5a-8a4b-683392c19051",
        "outputId": "23df628c-7208-435a-bc38-8639eede509c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[INFO][P2-Test] Load with_desc: /home/ssm-user/LAIDD/tox21/Data/test_data/test_data_with_desc.csv\n",
            "  -> Drop common-NaN columns first: 12\n",
            "  -> No columns contain NaN.\n",
            "[READY][P2-Test] saved -> /home/ssm-user/LAIDD/tox21/Data/test_data/test_data_processed.csv (rows=645, cols=207) | NaN columns dropped=0\n"
          ]
        }
      ],
      "source": [
        "# ====== Part 2 (TEST용, 단일 파일): _with_desc.csv 전처리 후 _2Ddesc.csv 저장\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# --- 입력/출력 경로 ---\n",
        "OUT_DIR         = \" \"\n",
        "WITH_DESC_FILE  = os.path.join(OUT_DIR, \"test_data_with_desc.csv\")\n",
        "SAVE_BASE       = os.path.join(OUT_DIR, \"test_data_processed\")\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# --- 공통 NaN 컬럼 드롭 리스트 ---\n",
        "DROP_LIST_CSV   = \" __/columns_with_nan_in_all_12_assays.csv\"\n",
        "\n",
        "def load_common_nan_columns_from_csv(csv_path: str) -> set[str]:\n",
        "    cols = set()\n",
        "    if not os.path.exists(csv_path):\n",
        "        print(f\"[P2-Test] Drop-list CSV not found: {csv_path} (skip)\")\n",
        "        return cols\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if \"column\" in df.columns:\n",
        "            cols.update(df[\"column\"].dropna().astype(str).str.strip().tolist())\n",
        "        else:\n",
        "            first_col = df.columns[0]\n",
        "            cols.update(df[first_col].dropna().astype(str).str.strip().tolist())\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] Failed to read CSV drop list: {csv_path} ({e})\")\n",
        "    return cols\n",
        "\n",
        "print(f\"\\n[INFO][P2-Test] Load with_desc: {WITH_DESC_FILE}\")\n",
        "df = pd.read_csv(WITH_DESC_FILE, dtype=str, engine=\"python\")\n",
        "\n",
        "required = {\"SMILES\", \"Sample ID\"}\n",
        "if not required.issubset(df.columns):\n",
        "    raise ValueError(f\"with_desc must have SMILES and Sample ID. Found: {list(df.columns)}\")\n",
        "\n",
        "df[\"SMILES\"]    = df[\"SMILES\"].astype(str).str.strip()\n",
        "df[\"Sample ID\"] = df[\"Sample ID\"].astype(str).str.strip()\n",
        "\n",
        "COMMON_NAN_COLS = load_common_nan_columns_from_csv(DROP_LIST_CSV)\n",
        "\n",
        "non_feat  = {\"Sample ID\", \"SMILES\"}\n",
        "feat_cols = [c for c in df.columns if c not in non_feat]\n",
        "if COMMON_NAN_COLS:\n",
        "    drop_cols_common = sorted(set(feat_cols).intersection(COMMON_NAN_COLS))\n",
        "    if drop_cols_common:\n",
        "        print(f\"  -> Drop common-NaN columns first: {len(drop_cols_common)}\")\n",
        "        df = df.drop(columns=drop_cols_common, errors=\"ignore\")\n",
        "        feat_cols = [c for c in feat_cols if c not in drop_cols_common]\n",
        "    else:\n",
        "        print(\"  -> No common-NaN columns to drop in this file.\")\n",
        "else:\n",
        "    print(\"  -> No common-NaN drop list loaded or list is empty.\")\n",
        "\n",
        "# 숫자화 후 float64로 통일\n",
        "X = df[feat_cols].apply(pd.to_numeric, errors=\"coerce\").astype(np.float64)\n",
        "\n",
        "# NaN 포함 열 전부 삭제\n",
        "nan_cols = X.columns[X.isna().any(axis=0)].tolist()\n",
        "if nan_cols:\n",
        "    print(f\"  -> Drop columns containing NaN ({len(nan_cols)}): \"\n",
        "          f\"{nan_cols[:5]}{'...' if len(nan_cols) > 5 else ''}\")\n",
        "    X = X.drop(columns=nan_cols)\n",
        "else:\n",
        "    print(\"  -> No columns contain NaN.\")\n",
        "\n",
        "if X.shape[1] == 0:\n",
        "    raise RuntimeError(\"No feature columns remain after dropping NaN columns. Check preprocessing settings.\")\n",
        "\n",
        "# 비유한값 최종 점검 (NaN/±inf 모두 없어야 함)\n",
        "assert np.isfinite(X.values).all(), \"Processed X still has non-finite values (NaN or ±inf).\"\n",
        "\n",
        "left_part = df.loc[:, [\"Sample ID\", \"SMILES\"]].reset_index(drop=True)\n",
        "X_final   = X.reset_index(drop=True)\n",
        "df_save   = pd.concat([left_part, X_final], axis=1)\n",
        "df_save.to_csv(SAVE_BASE + \".csv\", index=False)\n",
        "\n",
        "print(f\"[READY][P2-Test] saved -> {SAVE_BASE+'.csv'} \"\n",
        "      f\"(rows={len(df_save)}, cols={len(df_save.columns)}) | \"\n",
        "      f\"NaN columns dropped={len(nan_cols)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52fb0a40-a133-4dd5-8529-c770e246e22a",
      "metadata": {
        "scrolled": true,
        "id": "52fb0a40-a133-4dd5-8529-c770e246e22a",
        "outputId": "4349fd2e-615c-47c2-fb9b-362023cd97ff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MaxAbsEStateIndex</th>\n",
              "      <th>MaxEStateIndex</th>\n",
              "      <th>MinAbsEStateIndex</th>\n",
              "      <th>MinEStateIndex</th>\n",
              "      <th>qed</th>\n",
              "      <th>SPS</th>\n",
              "      <th>MolWt</th>\n",
              "      <th>HeavyAtomMolWt</th>\n",
              "      <th>ExactMolWt</th>\n",
              "      <th>NumValenceElectrons</th>\n",
              "      <th>...</th>\n",
              "      <th>fr_sulfide</th>\n",
              "      <th>fr_sulfonamd</th>\n",
              "      <th>fr_sulfone</th>\n",
              "      <th>fr_term_acetylene</th>\n",
              "      <th>fr_tetrazole</th>\n",
              "      <th>fr_thiazole</th>\n",
              "      <th>fr_thiocyan</th>\n",
              "      <th>fr_thiophene</th>\n",
              "      <th>fr_unbrch_alkane</th>\n",
              "      <th>fr_urea</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.030275</td>\n",
              "      <td>14.030275</td>\n",
              "      <td>0.039440</td>\n",
              "      <td>-1.257037</td>\n",
              "      <td>0.276843</td>\n",
              "      <td>31.018868</td>\n",
              "      <td>726.919</td>\n",
              "      <td>672.487</td>\n",
              "      <td>726.410483</td>\n",
              "      <td>284.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11.407017</td>\n",
              "      <td>11.407017</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-4.437336</td>\n",
              "      <td>0.262347</td>\n",
              "      <td>35.625000</td>\n",
              "      <td>430.087</td>\n",
              "      <td>420.007</td>\n",
              "      <td>428.944976</td>\n",
              "      <td>124.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12.707162</td>\n",
              "      <td>12.707162</td>\n",
              "      <td>0.046209</td>\n",
              "      <td>0.046209</td>\n",
              "      <td>0.540057</td>\n",
              "      <td>13.272727</td>\n",
              "      <td>287.322</td>\n",
              "      <td>274.218</td>\n",
              "      <td>287.105862</td>\n",
              "      <td>106.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13.168842</td>\n",
              "      <td>13.168842</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.356126</td>\n",
              "      <td>0.608509</td>\n",
              "      <td>10.680000</td>\n",
              "      <td>364.823</td>\n",
              "      <td>345.671</td>\n",
              "      <td>364.115397</td>\n",
              "      <td>132.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12.458058</td>\n",
              "      <td>12.458058</td>\n",
              "      <td>0.128272</td>\n",
              "      <td>-3.780944</td>\n",
              "      <td>0.779959</td>\n",
              "      <td>12.782609</td>\n",
              "      <td>351.855</td>\n",
              "      <td>333.711</td>\n",
              "      <td>351.069592</td>\n",
              "      <td>122.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>640</th>\n",
              "      <td>8.017361</td>\n",
              "      <td>8.017361</td>\n",
              "      <td>0.267361</td>\n",
              "      <td>0.267361</td>\n",
              "      <td>0.469276</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>92.163</td>\n",
              "      <td>84.099</td>\n",
              "      <td>92.029586</td>\n",
              "      <td>32.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>641</th>\n",
              "      <td>8.873357</td>\n",
              "      <td>8.873357</td>\n",
              "      <td>0.138819</td>\n",
              "      <td>0.138819</td>\n",
              "      <td>0.468960</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>219.285</td>\n",
              "      <td>198.117</td>\n",
              "      <td>219.158292</td>\n",
              "      <td>90.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>642</th>\n",
              "      <td>4.644676</td>\n",
              "      <td>4.644676</td>\n",
              "      <td>0.472222</td>\n",
              "      <td>0.472222</td>\n",
              "      <td>0.480265</td>\n",
              "      <td>9.285714</td>\n",
              "      <td>116.149</td>\n",
              "      <td>112.117</td>\n",
              "      <td>116.015667</td>\n",
              "      <td>38.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>643</th>\n",
              "      <td>11.178917</td>\n",
              "      <td>11.178917</td>\n",
              "      <td>0.264441</td>\n",
              "      <td>-1.134614</td>\n",
              "      <td>0.646146</td>\n",
              "      <td>19.190476</td>\n",
              "      <td>344.267</td>\n",
              "      <td>329.147</td>\n",
              "      <td>343.031288</td>\n",
              "      <td>112.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>644</th>\n",
              "      <td>4.906250</td>\n",
              "      <td>4.906250</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.548346</td>\n",
              "      <td>9.285714</td>\n",
              "      <td>114.169</td>\n",
              "      <td>108.121</td>\n",
              "      <td>114.013936</td>\n",
              "      <td>38.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>645 rows × 205 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     MaxAbsEStateIndex  MaxEStateIndex  MinAbsEStateIndex  MinEStateIndex  \\\n",
              "0            14.030275       14.030275           0.039440       -1.257037   \n",
              "1            11.407017       11.407017           0.000000       -4.437336   \n",
              "2            12.707162       12.707162           0.046209        0.046209   \n",
              "3            13.168842       13.168842           0.000000       -0.356126   \n",
              "4            12.458058       12.458058           0.128272       -3.780944   \n",
              "..                 ...             ...                ...             ...   \n",
              "640           8.017361        8.017361           0.267361        0.267361   \n",
              "641           8.873357        8.873357           0.138819        0.138819   \n",
              "642           4.644676        4.644676           0.472222        0.472222   \n",
              "643          11.178917       11.178917           0.264441       -1.134614   \n",
              "644           4.906250        4.906250           0.687500        0.687500   \n",
              "\n",
              "          qed        SPS    MolWt  HeavyAtomMolWt  ExactMolWt  \\\n",
              "0    0.276843  31.018868  726.919         672.487  726.410483   \n",
              "1    0.262347  35.625000  430.087         420.007  428.944976   \n",
              "2    0.540057  13.272727  287.322         274.218  287.105862   \n",
              "3    0.608509  10.680000  364.823         345.671  364.115397   \n",
              "4    0.779959  12.782609  351.855         333.711  351.069592   \n",
              "..        ...        ...      ...             ...         ...   \n",
              "640  0.469276   8.400000   92.163          84.099   92.029586   \n",
              "641  0.468960  21.000000  219.285         198.117  219.158292   \n",
              "642  0.480265   9.285714  116.149         112.117  116.015667   \n",
              "643  0.646146  19.190476  344.267         329.147  343.031288   \n",
              "644  0.548346   9.285714  114.169         108.121  114.013936   \n",
              "\n",
              "     NumValenceElectrons  ...  fr_sulfide  fr_sulfonamd  fr_sulfone  \\\n",
              "0                  284.0  ...         0.0           0.0         0.0   \n",
              "1                  124.0  ...         0.0           0.0         0.0   \n",
              "2                  106.0  ...         0.0           0.0         0.0   \n",
              "3                  132.0  ...         0.0           0.0         0.0   \n",
              "4                  122.0  ...         0.0           1.0         0.0   \n",
              "..                   ...  ...         ...           ...         ...   \n",
              "640                 32.0  ...         0.0           0.0         0.0   \n",
              "641                 90.0  ...         0.0           0.0         0.0   \n",
              "642                 38.0  ...         0.0           0.0         0.0   \n",
              "643                112.0  ...         0.0           0.0         0.0   \n",
              "644                 38.0  ...         0.0           0.0         0.0   \n",
              "\n",
              "     fr_term_acetylene  fr_tetrazole  fr_thiazole  fr_thiocyan  fr_thiophene  \\\n",
              "0                  0.0           0.0          0.0          0.0           0.0   \n",
              "1                  0.0           0.0          0.0          0.0           0.0   \n",
              "2                  0.0           0.0          0.0          0.0           0.0   \n",
              "3                  0.0           0.0          0.0          0.0           0.0   \n",
              "4                  0.0           0.0          0.0          0.0           0.0   \n",
              "..                 ...           ...          ...          ...           ...   \n",
              "640                0.0           0.0          0.0          0.0           0.0   \n",
              "641                0.0           0.0          0.0          0.0           0.0   \n",
              "642                0.0           1.0          0.0          0.0           0.0   \n",
              "643                0.0           0.0          0.0          0.0           0.0   \n",
              "644                0.0           0.0          0.0          0.0           0.0   \n",
              "\n",
              "     fr_unbrch_alkane  fr_urea  \n",
              "0                 0.0      0.0  \n",
              "1                 0.0      0.0  \n",
              "2                 0.0      0.0  \n",
              "3                 0.0      0.0  \n",
              "4                 0.0      0.0  \n",
              "..                ...      ...  \n",
              "640               0.0      0.0  \n",
              "641               0.0      0.0  \n",
              "642               0.0      0.0  \n",
              "643               0.0      0.0  \n",
              "644               0.0      0.0  \n",
              "\n",
              "[645 rows x 205 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3675d6c5-4ffd-4d7a-b054-c521bb68bbeb",
      "metadata": {
        "id": "3675d6c5-4ffd-4d7a-b054-c521bb68bbeb"
      },
      "source": [
        "### Part 3: test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88e95508-a7f9-43e1-bb3f-110bbbbb1089",
      "metadata": {
        "id": "88e95508-a7f9-43e1-bb3f-110bbbbb1089",
        "outputId": "22db65b1-aace-4cf4-ea0e-29f9e686ef8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TEST] Loading model & assays ...\n",
            "[TEST] #features expected by model: 205\n",
            "[TEST] Model internal n_features_in_: 205\n",
            "[TEST] Loading test data: /home/ssm-user/LAIDD/tox21/Data/test_data/test_data_processed.csv\n",
            "[TEST] Predicting probabilities ...\n",
            "[READY] Saved stacking-ready test probabilities -> /home/ssm-user/LAIDD/tox21/Results_imputer_inf/2D_predictions.csv\n",
            "        rows=645, assays=12\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "# ===================== 경로 설정 =====================\n",
        "MODEL_DIR   = \"  \"\n",
        "MODEL_PATH  = os.path.join(MODEL_DIR, \"multilabel_rf_best.joblib\")\n",
        "ASSAYS_PATH = os.path.join(MODEL_DIR, \"assays.json\")\n",
        "\n",
        "TEST_PATH   = \" \"  # 이미 전처리 완료본\n",
        "TEST_OUT    = os.path.join(MODEL_DIR, \"2D_predictions.csv\")    # 스태킹용 출력\n",
        "\n",
        "# ===================== 유틸 =====================\n",
        "def load_assays(path: str):\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"assays.json not found: {path}\")\n",
        "    with open(path, \"r\") as f:\n",
        "        assays = json.load(f)\n",
        "    if not isinstance(assays, list) or not assays:\n",
        "        raise ValueError(\"assays.json is not a non-empty list.\")\n",
        "    return assays\n",
        "\n",
        "def get_training_feature_names(pipe) -> list:\n",
        "    \"\"\"\n",
        "    학습 시 사용된 피처명(순서 포함)을 파이프라인에서 복구.\n",
        "    - 1순위: 첫 스텝(SimpleImputer 등)의 feature_names_in_\n",
        "    - 2순위: 파이프라인 자체의 feature_names_in_\n",
        "    \"\"\"\n",
        "    if hasattr(pipe, \"named_steps\") and \"imp\" in pipe.named_steps:\n",
        "        imp = pipe.named_steps[\"imp\"]\n",
        "        if hasattr(imp, \"feature_names_in_\"):\n",
        "            return list(imp.feature_names_in_)\n",
        "    if hasattr(pipe, \"feature_names_in_\"):\n",
        "        return list(pipe.feature_names_in_)\n",
        "    raise RuntimeError(\n",
        "        \"Cannot find training feature names in the fitted pipeline. \"\n",
        "        \"Ensure the model was trained with a pandas DataFrame so steps expose 'feature_names_in_'.\"\n",
        "    )\n",
        "\n",
        "# ===================== 메인 =====================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n[TEST] Loading model & assays ...\")\n",
        "    pipe = joblib.load(MODEL_PATH)       # Pipeline(SimpleImputer + MultiOutput(RandomForest))\n",
        "    assays = load_assays(ASSAYS_PATH)\n",
        "    expected_features = get_training_feature_names(pipe)\n",
        "    print(f\"[TEST] #features expected by model: {len(expected_features)}\")\n",
        "\n",
        "    # (선택) 내부 차원 로그\n",
        "    try:\n",
        "        n_expected_internal = pipe.named_steps[\"clf\"].estimators_[0].n_features_in_\n",
        "        print(f\"[TEST] Model internal n_features_in_: {n_expected_internal}\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    print(f\"[TEST] Loading test data: {TEST_PATH}\")\n",
        "    test_df = pd.read_csv(TEST_PATH, low_memory=False,\n",
        "                          dtype={\"Sample ID\":\"string\",\"SMILES\":\"string\"})\n",
        "    # 키 정리\n",
        "    test_df[\"Sample ID\"] = test_df[\"Sample ID\"].astype(\"string\").str.strip()\n",
        "    test_df[\"SMILES\"]    = test_df[\"SMILES\"].astype(\"string\").str.strip()\n",
        "\n",
        "    # 피처 부분만 분리\n",
        "    non_feat = {\"Sample ID\", \"SMILES\", \"toxicity\"}\n",
        "    test_feat_cols = [c for c in test_df.columns if c not in non_feat]\n",
        "    X_test = test_df[test_feat_cols].copy()\n",
        "\n",
        "    # 수치 변환 + 안전장치(±inf -> NaN)\n",
        "    X_test = X_test.apply(pd.to_numeric, errors=\"coerce\")\n",
        "    X_test = X_test.replace([np.inf, -np.inf], np.nan).astype(\"float64\")\n",
        "\n",
        "    # 학습 스키마로 정렬: 누락 컬럼은 자동으로 NaN 생성, 여분 컬럼은 드롭\n",
        "    exp_set = set(expected_features)\n",
        "    cur_set = set(X_test.columns)\n",
        "    missing = sorted(exp_set - cur_set)\n",
        "    extra   = sorted(cur_set - exp_set)\n",
        "\n",
        "    if missing:\n",
        "        print(f\"[TEST][WARN] Missing {len(missing)} feature(s) in test \"\n",
        "              f\"(filled as NaN). e.g., {missing[:5]}{'...' if len(missing)>5 else ''}\")\n",
        "    if extra:\n",
        "        print(f\"[TEST] Dropping {len(extra)} unexpected test feature(s). \"\n",
        "              f\"e.g., {extra[:5]}{'...' if len(extra)>5 else ''}\")\n",
        "\n",
        "    X_test = X_test.reindex(columns=expected_features)\n",
        "\n",
        "    assert list(X_test.columns) == list(expected_features)  # 학습 피처와 완전 동일\n",
        "\n",
        "    # ===== 예측 =====\n",
        "    print(\"[TEST] Predicting probabilities ...\")\n",
        "    proba_out = pipe.predict_proba(X_test)  # MultiOutputClassifier: list of (n,2) or ndarray (n,2) when single\n",
        "    proba_list = proba_out if isinstance(proba_out, list) else [proba_out]\n",
        "    prob_mat = np.column_stack([p[:, 1] for p in proba_list]).astype(np.float32)\n",
        "\n",
        "    # ===== 저장: Sample ID, SMILES + assay별 확률 =====\n",
        "    out_df = pd.concat(\n",
        "        [test_df.loc[:, [\"Sample ID\", \"SMILES\"]].reset_index(drop=True),\n",
        "         pd.DataFrame(prob_mat, columns=assays)],\n",
        "        axis=1\n",
        "    )\n",
        "    os.makedirs(os.path.dirname(TEST_OUT), exist_ok=True)\n",
        "    out_df.to_csv(TEST_OUT, index=False)\n",
        "    print(f\"[READY] Saved stacking-ready test probabilities -> {TEST_OUT}\")\n",
        "    print(f\"        rows={len(out_df)}, assays={len(assays)}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}